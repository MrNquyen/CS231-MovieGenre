{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.functional as F\n",
    "\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "\n",
    "os.chdir('F:\\\\UNIVERSITY\\\\UNIVERSITY_DOCUMENTS\\\\CS231\\\\doan_v2')\n",
    "\n",
    "from skimage import io, transform\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from sklearn.metrics import jaccard_score, hamming_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import ClassifierChain, MultiOutputClassifier, MultiOutputRegressor \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Linear, ReLU, Sigmoid, Softmax, Dropout, Sequential\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.models import vgg16, resnet50, densenet169\n",
    "from torchvision.models.vgg import VGG16_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json\n",
    "def load_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        film_dic = json.load(file)\n",
    "        return film_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'action', 'adventure', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'horror', 'mystery', 'thriller', 'romance', 'scifi', 'others'\n",
    "]\n",
    "\n",
    "config = {\n",
    "    'img_size': (224, 224),\n",
    "    'epochs': 10,\n",
    "    'batches': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieGenreDataset():\n",
    "    def __init__(\n",
    "            self, \n",
    "            annot_path='data/train_new.json',\n",
    "            features_dir='features_VGG',\n",
    "            classes=[\n",
    "                'action', 'adventure', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'horror', 'mystery', 'thriller', 'romance', 'scifi', 'others'\n",
    "            ],\n",
    "        ) -> None:\n",
    "        annotation = load_json(annot_path)\n",
    "        set_name = os.path.basename(annot_path).split('.')[0]\n",
    "        \n",
    "        # Load X\n",
    "        npy_features_name = os.listdir(features_dir)\n",
    "        npy_file_names = [f'{id}.npy' for id in annotation.keys() if f'{id}.npy' in npy_features_name]\n",
    "        npy_file_paths = [os.path.join(features_dir, npy_file_name) for npy_file_name in npy_file_names ]\n",
    "\n",
    "        self.X = np.array([\n",
    "            np.load(npy_file_path) \n",
    "            for npy_file_path in tqdm(npy_file_paths, desc=f\"Loading X_{set_name}\")\n",
    "        ])\n",
    "        \n",
    "        # Load y\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        mlb.fit([classes])\n",
    "\n",
    "        genres = [\n",
    "            val['genre'] \n",
    "            for val in tqdm(annotation.values(), desc=\"Loading y\")\n",
    "        ]\n",
    "        self.y = mlb.transform(genres)\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.X, self.y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *DENSENET*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading X_train_new: 100%|██████████| 4863/4863 [01:54<00:00, 42.53it/s]\n",
      "Loading y: 100%|██████████| 4863/4863 [00:00<00:00, 607737.93it/s]\n",
      "Loading X_val: 100%|██████████| 2359/2359 [00:55<00:00, 42.81it/s]\n",
      "Loading y: 100%|██████████| 2359/2359 [00:00<00:00, 784768.65it/s]\n",
      "Loading X_test: 100%|██████████| 2511/2511 [00:54<00:00, 45.78it/s]\n",
      "Loading y: 100%|██████████| 2513/2513 [00:00<00:00, 627883.84it/s]\n"
     ]
    }
   ],
   "source": [
    "train_Densenet169_dataset = MovieGenreDataset(\n",
    "    annot_path='data/train_new.json',\n",
    "    features_dir='features_Densenet169',\n",
    ")\n",
    "\n",
    "val_Densenet169_dataset = MovieGenreDataset(\n",
    "    annot_path='data/val.json',\n",
    "    features_dir='features_Densenet169',\n",
    ")\n",
    "\n",
    "test_Densenet169_dataset = MovieGenreDataset(\n",
    "    annot_path='data/test.json',\n",
    "    features_dir='features_Densenet169',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Densenet, y_train_Densenet = train_Densenet169_dataset.get_data()\n",
    "X_val_Densenet, y_val_Densenet = val_Densenet169_dataset.get_data()\n",
    "X_test_Densenet, y_test_Densenet = test_Densenet169_dataset.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *DENSENET*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_Densenet = PCA(n_components=0.4)\n",
    "X_train_Densenet_new = pca_Densenet.fit_transform(X_train_Densenet)\n",
    "X_val_Densenet_new = pca_Densenet.transform(X_val_Densenet)\n",
    "X_test_Densenet_new = pca_Densenet.transform(X_test_Densenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MODELING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *MultiOutputClassifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "class MultiOutputRegressorRandomForest():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.model_tuning = None\n",
    "        self.params = {\n",
    "            'estimator__bootstrap': [True, False],\n",
    "            'estimator__max_depth': [30, 50, 70, 90, None],\n",
    "            'estimator__min_samples_leaf': [1, 2, 4],\n",
    "            'estimator__min_samples_split': [2, 5, 10],\n",
    "            'estimator__n_estimators': [50, 100],\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print('Fitting model')\n",
    "        self.model = MultiOutputRegressor(RandomForestRegressor())\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def fit_tuning(self, X, y):\n",
    "        print('Fitting tuning model')\n",
    "        estimator = MultiOutputRegressor(RandomForestRegressor())\n",
    "        self.model_tuning = RandomizedSearchCV(\n",
    "            estimator=estimator, \n",
    "            param_distributions=self.params, \n",
    "            random_state=0,\n",
    "            n_iter=2,\n",
    "            verbose=True,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        self.model_tuning.fit(X, y)\n",
    "\n",
    "    def predict(self, X, mode='default'):\n",
    "        print('Prediction')\n",
    "        if mode=='default' and self.model != None:\n",
    "            prediction = self.model.predict(X)\n",
    "        elif mode=='tune' and self.model_tuning != None:\n",
    "            prediction = self.model_tuning.predict(X)\n",
    "        else:\n",
    "            print('Cant predict the X set !!')\n",
    "            prediction = np.array([])\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "class MultiOutputClassifierLogisticRegression():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.model_tuning = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print('Fitting model')\n",
    "        self.model = MultiOutputClassifier(LogisticRegression())\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X, mode='default'):\n",
    "        print('Prediction')\n",
    "        if mode=='default' and self.model != None:\n",
    "            prediction = self.model.predict(X)\n",
    "        elif mode=='tune' and self.model_tuning != None:\n",
    "            prediction = self.model_tuning.predict(X)\n",
    "        else:\n",
    "            print('Cant predict the X set !!')\n",
    "            prediction = np.array([])\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *No Tuning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n"
     ]
    }
   ],
   "source": [
    "# Densenet169\n",
    "rf_dense = MultiOutputRegressorRandomForest()\n",
    "rf_dense.fit(X_train_Densenet_new, y_train_Densenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "Prediction\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "prediction_rf_dense_test = rf_dense.predict(X_test_Densenet_new)\n",
    "prediction_rf_dense_val = rf_dense.predict(X_val_Densenet_new)\n",
    "np.save('evaluation/prediction_rf_dense_test.npy', prediction_rf_dense_test)\n",
    "np.save('evaluation/prediction_rf_dense_val.npy', prediction_rf_dense_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Logistic Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n"
     ]
    }
   ],
   "source": [
    "# Densenet169\n",
    "logistic_r_dense = MultiOutputClassifierLogisticRegression()\n",
    "logistic_r_dense.fit(X_train_Densenet_new, y_train_Densenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "Prediction\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "prediction_logistic_r_dense_test = logistic_r_dense.predict(X_test_Densenet_new)\n",
    "prediction_logistic_r_dense_val = logistic_r_dense.predict(X_val_Densenet_new)\n",
    "np.save('evaluation/prediction_logistic_r_dense_test.npy', prediction_logistic_r_dense_test)\n",
    "np.save('evaluation/prediction_logistic_r_dense_val.npy', prediction_logistic_r_dense_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *SVC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.svm import SVC\n",
    "class MultiOutputClassifierSVC():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.model_tuning = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print('Fitting model')\n",
    "        self.model = MultiOutputClassifier(SVC())\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X, mode='default'):\n",
    "        print('Prediction')\n",
    "        if mode=='default' and self.model != None:\n",
    "            prediction = self.model.predict(X)\n",
    "        elif mode=='tune' and self.model_tuning != None:\n",
    "            prediction = self.model_tuning.predict(X)\n",
    "        else:\n",
    "            print('Cant predict the X set !!')\n",
    "            prediction = np.array([])\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n"
     ]
    }
   ],
   "source": [
    "svc_dense = MultiOutputClassifierSVC()\n",
    "svc_dense.fit(X_train_Densenet_new, y_train_Densenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "Prediction\n"
     ]
    }
   ],
   "source": [
    "# # Predict\n",
    "prediction_svc_dense_test = svc_dense.predict(X_test_Densenet_new)\n",
    "prediction_svc_dense_val = svc_dense.predict(X_val_Densenet_new)\n",
    "np.save('evaluation/prediction_svc_dense_test.npy', prediction_svc_dense_test)\n",
    "np.save('evaluation/prediction_svc_dense_val.npy', prediction_svc_dense_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

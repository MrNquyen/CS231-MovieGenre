{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv5ayzGhfY2b",
        "outputId": "913de810-0eae-43ba-cf53-55a79cb4c185"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DG01odR2RDOP"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "# import tensorflow_hub as hub\n",
        "\n",
        "from datetime import datetime\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.calibration import calibration_curve\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir('F:\\\\UNIVERSITY\\\\UNIVERSITY_DOCUMENTS\\\\CS231\\\\doan_v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yyCbEaP8RDOX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential, clone_model\n",
        "from keras.layers import InputLayer, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, AveragePooling2D\n",
        "from keras.layers import Dense, InputLayer, Flatten, Normalization, SimpleRNN, Embedding, LSTM, Bidirectional, GRU\n",
        "# from keras.layers.normalization import LRN2D\n",
        "\n",
        "from keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
        "from keras.optimizers import SGD, RMSprop, Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXfmss3jRDOZ"
      },
      "source": [
        "# **Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bB8m6ZBvRDOb"
      },
      "outputs": [],
      "source": [
        "def load_json(path):\n",
        "    with open(path, 'r') as file:\n",
        "        json_file = json.load(file)\n",
        "        return json_file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuKOtpSlRMuH"
      },
      "source": [
        "# **Load Repo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvyMV_cUYp83",
        "outputId": "bc22eddc-b48a-423e-edac-99000e3546bf"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/MrNquyen/Movie-Genres-CS231.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0xFeB50Y2R3",
        "outputId": "93475d03-ddcb-417b-8cdc-d989c86b63b6"
      },
      "outputs": [],
      "source": [
        "# %cd Movie-Genres-CS231"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q69sLR4uRDOc"
      },
      "source": [
        "# **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "L1gHNvC2RDOd"
      },
      "outputs": [],
      "source": [
        "train_path = 'data/train_new.json'\n",
        "val_path = 'data/val.json'\n",
        "test_path = 'data/test.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nF-xHuC0RDOd"
      },
      "outputs": [],
      "source": [
        "train_annot = load_json(train_path)\n",
        "val_annot = load_json(val_path)\n",
        "test_annot = load_json(test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tP7iWSiRDOe"
      },
      "source": [
        "# **Train Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0KOw1EBDRDOe"
      },
      "outputs": [],
      "source": [
        "def create_df(annot):\n",
        "    data = {\n",
        "        'id': [],\n",
        "        'name': [],\n",
        "        'genre': [],\n",
        "        'img_url': [],\n",
        "        'img_path': [],\n",
        "    }\n",
        "    available_images = os.listdir('features_Resnet50')\n",
        "    for key, val in annot.items():\n",
        "        if f'{key}.npy' not in available_images:\n",
        "            continue\n",
        "        data['id'].append(key)\n",
        "        for small_key in val.keys():\n",
        "            data[small_key].append(val[small_key])\n",
        "    return pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5pDujNHwRDOf"
      },
      "outputs": [],
      "source": [
        "# X_train, y_train\n",
        "train_df, val_df, test_df = create_df(train_annot), create_df(val_annot), create_df(test_annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, y_train = train_df['id'], train_df['genre']\n",
        "X_val, y_val = val_df['id'], val_df['genre']\n",
        "X_test, y_test = test_df['id'], test_df['genre']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3fb1ZG0DRDOf"
      },
      "outputs": [],
      "source": [
        "# y transform\n",
        "classes_ = [\n",
        "    'action', 'adventure', 'comedy', 'crime', 'documentary', 'drama', 'fantasy', 'horror', 'mystery', 'thriller', 'romance', 'scifi', 'others'\n",
        "]\n",
        "label2id = {class_: i for i, class_ in enumerate(classes_)}\n",
        "\n",
        "# Onehot Encode\n",
        "mlb = MultiLabelBinarizer()\n",
        "mlb.fit([classes_])\n",
        "\n",
        "# Multilabel\n",
        "y_train_new = mlb.transform(y_train).astype(float)\n",
        "y_val_new = mlb.transform(y_val).astype(float)\n",
        "y_test_new = mlb.transform(y_test).astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCjpwKyhRDOg"
      },
      "source": [
        "# **Load Image Tensor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Rlnfp3qaRDOg"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "CHANNELS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HrKxW6D_RDOh"
      },
      "outputs": [],
      "source": [
        "def parse_function(id, feature_dir='features_Resnet50'):\n",
        "    npy_path = f'{feature_dir}/{id}.npy'\n",
        "    image_features = np.load(npy_path)\n",
        "    return image_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/4861 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4861/4861 [01:36<00:00, 50.27it/s]\n",
            "100%|██████████| 2511/2511 [00:49<00:00, 50.54it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "X_train_new = np.array([parse_function(id) for id in tqdm(X_train)])\n",
        "X_test_new = np.array([parse_function(id) for id in tqdm(X_test)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4861/4861 [01:39<00:00, 48.92it/s]\n",
            "100%|██████████| 2511/2511 [00:52<00:00, 47.97it/s]\n"
          ]
        }
      ],
      "source": [
        "X_train_densenet = np.array([parse_function(id, feature_dir='features_Densenet169') for id in tqdm(X_train)])\n",
        "X_test_densenet = np.array([parse_function(id, feature_dir='features_Densenet169') for id in tqdm(X_test)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIWpNAYNRDOk"
      },
      "source": [
        "# **MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ghtz07vFRDOk"
      },
      "source": [
        "## ***VGG16***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,704,960</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,704,960\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │         \u001b[38;5;34m1,677\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,837,837</span> (7.01 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,837,837\u001b[0m (7.01 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,837,837</span> (7.01 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,837,837\u001b[0m (7.01 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_vgg = Sequential([\n",
        "    InputLayer((4096,)),\n",
        "    Dense(\n",
        "        units=1024,\n",
        "        activation='relu',\n",
        "    ),\n",
        "    Dense(\n",
        "        units=128,\n",
        "        activation='relu',\n",
        "    ),\n",
        "    Dense(\n",
        "        units=len(classes_),\n",
        "        activation='sigmoid',\n",
        "    ),\n",
        "])\n",
        "model_vgg.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "g7aEPwI2RDOm"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def macro_soft_f1(y, y_hat):\n",
        "    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
        "    Use probability values instead of binary predictions.\n",
        "\n",
        "    Args:\n",
        "        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
        "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "\n",
        "    Returns:\n",
        "        cost (scalar Tensor): value of the cost function for the batch\n",
        "    \"\"\"\n",
        "    y = tf.cast(y, tf.float32)\n",
        "    y_hat = tf.cast(y_hat, tf.float32)\n",
        "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
        "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
        "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
        "    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
        "    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n",
        "    macro_cost = tf.reduce_mean(cost) # average on all labels\n",
        "    return macro_cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "8OEvjINvRDOm"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def macro_f1(y, y_hat, thresh=0.5):\n",
        "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
        "\n",
        "    Args:\n",
        "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
        "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "        thresh: probability value above which we predict positive\n",
        "\n",
        "    Returns:\n",
        "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
        "    \"\"\"\n",
        "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
        "    y = tf.cast(y, tf.float32)\n",
        "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
        "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
        "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
        "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
        "    macro_f1 = tf.reduce_mean(f1)\n",
        "    return macro_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "-MqVjFWeRDOm"
      },
      "outputs": [],
      "source": [
        "# Optimizer and Loss function\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "loss_fn = macro_soft_f1\n",
        "metrics = [macro_f1]\n",
        "# callback = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Compile\n",
        "model_vgg.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_fn,\n",
        "    metrics=metrics\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1000, 13), (1000, 4096))"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# y_train_new.shape, X_train_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O50bLu-3RDOm",
        "outputId": "7819327c-1135-45d3-b1a7-98226fa96aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 296ms/step - loss: 0.6499 - macro_f1: 0.3501 - val_loss: 0.6985 - val_macro_f1: 0.2996\n",
            "Epoch 2/2\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 304ms/step - loss: 0.6503 - macro_f1: 0.3497 - val_loss: 0.6985 - val_macro_f1: 0.2996\n"
          ]
        }
      ],
      "source": [
        "# Fit model\n",
        "history_vgg = model_vgg.fit(\n",
        "    X_train_new, y_train_new,\n",
        "    batch_size=64,\n",
        "    epochs=2,\n",
        "    validation_data=(X_test_new, y_test_new),\n",
        "    # validation_data=val_ds,\n",
        "    # callbacks=[callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "collapsed": true,
        "id": "KbRYLga0YOkp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step\n"
          ]
        }
      ],
      "source": [
        "# prediction = []\n",
        "# for batch in test_ds:\n",
        "#     pred = model_vgg.predict(batch[0])\n",
        "#     prediction.append(pred)\n",
        "\n",
        "# prediction_concat = np.concatenate(prediction)\n",
        "pred = model_vgg.predict(X_test_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYHvm-XtkV7i"
      },
      "outputs": [],
      "source": [
        "# def thresholding_results(y_logits, thres=0.5):\n",
        "#     y_logits_copy = y_logits.copy()\n",
        "#     y_logits_copy[y_logits_copy >= thres] = 1\n",
        "#     y_logits_copy[y_logits_copy < thres] = 0\n",
        "#     return y_logits_copy\n",
        "\n",
        "# y_pred = thresholding_results(prediction_concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "qR940fMHdl5w"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/UNIVERSITY/SUBJECT/CS231/doan/transfer_learning\n",
        "os.chdir('F:\\\\UNIVERSITY\\\\UNIVERSITY_DOCUMENTS\\\\CS231\\\\doan_v2\\\\evaluation')\n",
        "np.save('vgg_layer', pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mozq1EmqgIyS"
      },
      "outputs": [],
      "source": [
        "np.save('y_test', y_test_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ***DENSE***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4863, 4096)"
            ]
          },
          "execution_count": 245,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dense = Sequential([\n",
        "    InputLayer(X_train_new[0].shape),\n",
        "    Dense(\n",
        "        units=1024,\n",
        "        activation='relu',\n",
        "    ),\n",
        "    Dense(\n",
        "        units=128,\n",
        "        activation='relu',\n",
        "    ),\n",
        "    Dense(\n",
        "        units=len(classes_),\n",
        "        activation='sigmoid',\n",
        "    ),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,195,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,677</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m4,195,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │         \u001b[38;5;34m1,677\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,328,205</span> (16.51 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,328,205\u001b[0m (16.51 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,328,205</span> (16.51 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,328,205\u001b[0m (16.51 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_dense.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def macro_soft_f1(y, y_hat):\n",
        "    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
        "    Use probability values instead of binary predictions.\n",
        "\n",
        "    Args:\n",
        "        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
        "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "\n",
        "    Returns:\n",
        "        cost (scalar Tensor): value of the cost function for the batch\n",
        "    \"\"\"\n",
        "    y = tf.cast(y, tf.float32)\n",
        "    y_hat = tf.cast(y_hat, tf.float32)\n",
        "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
        "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
        "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
        "    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
        "    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n",
        "    macro_cost = tf.reduce_mean(cost) # average on all labels\n",
        "    return macro_cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def macro_f1(y, y_hat, thresh=0.5):\n",
        "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
        "\n",
        "    Args:\n",
        "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
        "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
        "        thresh: probability value above which we predict positive\n",
        "\n",
        "    Returns:\n",
        "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
        "    \"\"\"\n",
        "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
        "    y = tf.cast(y, tf.float32)\n",
        "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
        "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
        "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
        "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
        "    macro_f1 = tf.reduce_mean(f1)\n",
        "    return macro_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimizer and Loss function\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "loss_fn = macro_soft_f1\n",
        "metrics = [macro_f1]\n",
        "callback = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Compile\n",
        "model_dense.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_fn,\n",
        "    metrics=metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.6655 - macro_f1: 0.3293 - val_loss: 0.6984 - val_macro_f1: 0.2995\n",
            "Epoch 2/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.6504 - macro_f1: 0.3509 - val_loss: 0.6937 - val_macro_f1: 0.3082\n",
            "Epoch 3/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.6429 - macro_f1: 0.3593 - val_loss: 0.6984 - val_macro_f1: 0.2994\n",
            "Epoch 4/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.6304 - macro_f1: 0.3731 - val_loss: 0.6884 - val_macro_f1: 0.3112\n",
            "Epoch 5/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.6288 - macro_f1: 0.3767 - val_loss: 0.6883 - val_macro_f1: 0.3120\n",
            "Epoch 6/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.6272 - macro_f1: 0.3758 - val_loss: 0.6943 - val_macro_f1: 0.3049\n",
            "Epoch 7/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.6262 - macro_f1: 0.3748 - val_loss: 0.6876 - val_macro_f1: 0.3105\n",
            "Epoch 8/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.6219 - macro_f1: 0.3823 - val_loss: 0.6888 - val_macro_f1: 0.3090\n",
            "Epoch 9/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.6110 - macro_f1: 0.3926 - val_loss: 0.6865 - val_macro_f1: 0.3126\n",
            "Epoch 10/10\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.6182 - macro_f1: 0.3861 - val_loss: 0.6905 - val_macro_f1: 0.3082\n"
          ]
        }
      ],
      "source": [
        "# Fit model\n",
        "history_dense = model_dense.fit(\n",
        "    X_train_new, y_train_new,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_data=(X_test_new, y_test_new),\n",
        "    # validation_data=val_ds,\n",
        "    callbacks=[callback],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
          ]
        }
      ],
      "source": [
        "# prediction = []\n",
        "# for batch in test_ds:\n",
        "#     pred = model_vgg.predict(batch[0])\n",
        "#     prediction.append(pred)\n",
        "\n",
        "# prediction_concat = np.concatenate(prediction)\n",
        "pred = model_dense.predict(X_test_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/UNIVERSITY/SUBJECT/CS231/doan/transfer_learning\n",
        "os.chdir('F:\\\\UNIVERSITY\\\\UNIVERSITY_DOCUMENTS\\\\CS231\\\\doan_v2\\\\evaluation')\n",
        "np.save('resnet_layer', pred)\n",
        "np.save('y_test_resnet_layer', y_test_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **RESNET50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Do the same change the feature_dir to load Input Feature"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
